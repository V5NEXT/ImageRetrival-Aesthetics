{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained:\n",
    "\n",
    "- VGG-16 and VGG-19: These CNNs were trained on the ImageNet dataset, and are known for their ability to classify images with high accuracy. They can be fine-tuned for other tasks, such as image similarity.\n",
    "\n",
    "- Inception v3: This CNN was also trained on the ImageNet dataset and is known for its efficiency and good performance on a wide range of image recognition tasks.\n",
    "\n",
    "- ResNet-50, ResNet-101, and ResNet-152: These CNNs are trained on the ImageNet dataset and are known for their deep architecture and good performance. They are a popular choice for image similarity and other image recognition tasks.\n",
    "\n",
    "- MobileNet: This CNN is designed to be efficient and fast, making it suitable for use on mobile devices. It is trained on the ImageNet dataset and can be used for image similarity and other image recognition tasks.\n",
    "\n",
    "Similarity:\n",
    "\n",
    "- cosine similarity\n",
    "- euclidean distance\n",
    "- manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, InceptionV3,\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import DistanceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = \"dataset/test.jpg\"\n",
    "dataset_path = \"dataset_test/dandelion/\"\n",
    "image_paths = os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading models\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "vgg_model.trainable = False\n",
    "\n",
    "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "inception_model.trainable = False\n",
    "\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "resnet_model.trainable = False\n",
    "\n",
    "models = {'VGG16': vgg_model, \n",
    "          'InceptionV3': inception_model, \n",
    "          'ResNet50': resnet_model,\n",
    "        #   'color': opencv_model1,\n",
    "        #   'shapes':opencv_model2\n",
    "          }\n",
    "\n",
    "def extract_features_image(model, image):\n",
    "    image = keras.preprocessing.image.img_to_array(image)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    if model == 'VGG16':\n",
    "        image = keras.applications.vgg16.preprocess_input(image)\n",
    "    elif model == 'InceptionV3':\n",
    "        image = keras.applications.inception_v3.preprocess_input(image)\n",
    "    elif model == 'ResNet50':\n",
    "        image = keras.applications.resnet50.preprocess_input(image)\n",
    "    features = model.predict(image, batch_size=1)\n",
    "    return features\n",
    "\n",
    "image_test = keras.preprocessing.image.load_img(test_image)\n",
    "features_test = extract_features_image('ResNet50', image_test)\n",
    "# features1 = features1.flatten()\n",
    "# euclidean_dis = euclidean_distances(features1.reshape(1,-1),features2.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, images_path):\n",
    "    features = []\n",
    "    for image_path in os.listdir(images_path):\n",
    "        image = keras.preprocessing.image.load_img(os.path.join(images_path,image_path))\n",
    "        image_features = model.predict(preprocess_input(image))\n",
    "        features.append(image_features)\n",
    "    return np.array(features)\n",
    "\n",
    "dataset_features = extract_features(vgg_model, dataset_path)\n",
    "query_image = keras.preprocessing.image.load_img(test_image)\n",
    "query_image_features = extract_features(vgg_model, query_image)\n",
    "\n",
    "#compute similarity measure\n",
    "similarities = []\n",
    "for i, img_features in enumerate(dataset_features):\n",
    "    # compute cosine similarity\n",
    "    cosine_sim = cosine_similarity(query_image_features, img_features)\n",
    "    # compute euclidean distance\n",
    "    euclidean_dis = euclidean_distances(query_image_features, img_features)\n",
    "\n",
    "    #manhattan distance\n",
    "    manhattan_distance = manhattan_distance(query_image_features, img_features)\n",
    "    \n",
    "    similarities.append((i, cosine_sim))\n",
    "    \n",
    "#sort similarities in descending order\n",
    "similarities.sort(key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained CNN\n",
    "model = ResNet50(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# Load the images and extract the features using the pre-trained CNN\n",
    "images = []\n",
    "features = []\n",
    "for image_path in image_paths:\n",
    "    image_path = os.path.join(dataset_path, image_path)\n",
    "    image = load_img(image_path, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "    images.append(image)\n",
    "    feature = model.predict(image.reshape((1, *image.shape)))\n",
    "    feature = feature.flatten()\n",
    "    features.append(feature)\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=8)\n",
    "kmeans.fit(features)\n",
    "\n",
    "# Get the cluster labels for each image\n",
    "labels = kmeans.predict(features)\n",
    "\n",
    "# Visualize the clusters\n",
    "for label, image in zip(labels, images):\n",
    "  plt.imshow(image)\n",
    "  plt.title(\"Cluster: {}\".format(label))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeaturesResnet(image_path):\n",
    "    images = []\n",
    "    features = []\n",
    "    image = load_img(image_path, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "    images.append(image)\n",
    "    feature = model.predict(image.reshape((1, *image.shape)))\n",
    "    feature = feature.flatten()\n",
    "    features.append(feature)\n",
    "    return images, features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Euclidean distance: 'euclidean'\n",
    "- Manhattan distance: 'manhattan'\n",
    "- Cosine similarity: 'cosine'\n",
    "- Pearson correlation coefficient: 'correlation'\n",
    "- Jaccard coefficient: 'jaccard'\n",
    "- Chebyshev distance: 'chebyshev'\n",
    "- Minkowski distance: 'minkowski'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kateb\\anaconda3\\envs\\newbase\\lib\\site-packages\\sklearn\\neighbors\\_distance_metric.py:10: FutureWarning: sklearn.neighbors.DistanceMetric has been moved to sklearn.metrics.DistanceMetric in 1.0. This import path will be removed in 1.3\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Distances\n",
    "# Euclidean distance\n",
    "euclidean_distance = DistanceMetric.get_metric('euclidean')\n",
    "# Manhattan distance\n",
    "manhattan_distance = DistanceMetric.get_metric('manhattan')\n",
    "# Cosine similarity\n",
    "# Define a function that calculates the cosine distance\n",
    "def cosine_distance(X, Y=None):\n",
    "    similarity = cosine_similarity(X, Y)\n",
    "    return 1 - similarity\n",
    "\n",
    "# Create a DistanceMetric instance for the cosine distance\n",
    "cosine_distance = DistanceMetric.get_metric(cosine_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 231ms/step\n"
     ]
    }
   ],
   "source": [
    "test_image = \"dataset/test.jpg\"\n",
    "test_img, features_test = extractFeaturesResnet(test_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 (default, Nov 15 2020, 08:30:55) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e08ebe62f7559bc39cb69aef352317b2b1aa67e44a4847c8dc1246ae334a2e80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
